{
  "name": "collections/blog/posts/62c20ab88d1d",
  "__resolveType": "blog/loaders/Blogpost.ts",
  "post": {
    "authors": [
      {
        "name": "Rafael Crespo",
        "email": "rafael@decocms.com",
        "avatar": "https://assets.decocache.com/decocms/d377d0fc-343d-4f45-84aa-c7e1da1beaf0/Luciano-Junior-1.png",
        "jobTitle": "Co-founder"
      }
    ],
    "categories": [
      {
        "name": "Product",
        "slug": "product"
      }
    ],
    "imageCarousel": {
      "banners": []
    },
    "extraProps": [],
    "aggregateRating": {
      "@type": "AggregateRating"
    },
    "review": [],
    "contentRating": [],
    "interactionStatistic": {
      "@type": "InteractionCounter",
      "image": null,
      "video": null
    },
    "image": "https://assets.decocache.com/decocms/79833234-6d89-4680-b537-5804259722f3/blog-post-1.png",
    "title": "The architecture of an AI-native company",
    "date": "2025-12-19",
    "content": "<p>There’s a leadership posture forming around AI that looks less like “spread adoption” and more like preparation.</p><p>Not every organization is ready to ship agents into production. Not every use case makes sense. And yes, there’s hype. But leaders who believe an autonomous future is coming are already asking a more concrete question:</p><p>What needs to be true for AI to compound inside an enterprise, instead of fragmenting into disconnected experiments?</p><p>This post is our current answer. We’ll go over what we think every AI-native enterprise needs, and why starting with context infrastructure changes everything above it.</p><hr><h2><br>The production gap </h2><p>2025 made the contrast hard to miss: AI can look great in controlled settings, but the gains don’t automatically carry into mature systems—large codebases, messy workflows, and regulated environments.</p><p>The evidence points in the same direction.<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://arxiv.org/abs/2302.06590\"> In a controlled greenfield task</a>, developers using Copilot completed the work ~55.8% faster.<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/\"> In a randomized trial</a> with experienced developers working in their own familiar repos, allowing AI assistance made them ~19% slower.</p><p>This is the production gap: the hard part isn’t getting a model to do something once. It’s making the behavior repeatable, auditable, and cost-predictable as both the tool surface and the organization grow.</p><hr><p></p><h2>What goes wrong when enterprises try to operationalize AI</h2><p>The loud story of 2025 was models, agents, frameworks, and promises. The quieter story happened inside companies: teams trying to make AI part of daily operations, and repeatedly hitting the same constraints around access control, debugging, and cost.</p><p>That’s why the year produced both impressive demos and underwhelming production outcomes. A lot of “AI transformation” stayed stuck as budget-driven experimentation, without a credible path to reliability.</p><p>When teams do push forward, three problems tend to show up together:</p><p></p><h3>1) Autonomy</h3><p>Teams want to build and ship AI apps quickly, but each initiative gets bottlenecked by infrastructure tickets, security reviews, and bespoke integration work.</p><h3>2) Context</h3><p>Enterprise knowledge is spread across dozens of systems. Agents don’t get the full picture, and teams rebuild the same connectors and retrieval logic over and over.</p><h3>3) Governance</h3><p>There’s no central way to enforce SSO, audit trails, access policies, or cost controls. Shadow AI spreads. Compliance escalates. Costs become hard to attribute and limit.</p><p>These pressures usually push orgs into one of two failure modes:</p><p><strong>Path 1 </strong>— Build an internal AI platform from scratch, results never come</p><p>Centralizing early can be the right instinct, but it often becomes a long infrastructure program. Teams wait. The business keeps operating on “manual + meetings” while the platform backlog grows.</p><p><strong>Path 2</strong> — A dozen tools later, nobody trusts the outputs</p><p>Every team adopts its own agent framework, copilots, MCP servers, and credentials. Progress is fast until it isn’t: access sprawl, unclear audit trails, no cost attribution, inconsistent behavior, and no supported path to production.</p><p>In both paths, you get activity, but the improvements don’t compound. Compounding requires a setup where teams can move fast without bypassing governance, and platform teams can enforce policies without becoming the bottleneck.</p><hr><h2>Our thesis: what needs to be true</h2><ul><li><p>Context infrastructure to connect and govern access to tools/data (where an MCP Mesh fits).</p></li><li><p>Reusable building blocks so teams can package capabilities with consistent schemas and permissions (where MCP Studio fits).</p></li><li><p>A path to adoption where humans and agents can run work safely and distribute what works (apps/modules, and eventually store-like distribution).</p></li></ul><p></p><p><em>Different companies will draw the boundaries differently. But if you’re missing the first two, scaling agentic software tends to either stall (too much centralization) or sprawl (too much fragmentation).</em></p><p></p><hr><h2>Why now: the MCP convergence</h2><p>In 2024, MCP looked like “a protocol some people use to connect tools.” By late 2025, it’s increasingly a shared substrate that major platforms are converging on.</p><p>Three signals made the direction hard to ignore:</p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation\">Anthropic donated MCP to the Linux</a> Foundation’s Agentic AI Foundation (AAIF), explicitly placing it under neutral governance. </p></li></ul><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://developers.openai.com/apps-sdk/quickstart\">OpenAI’s Apps SDK builds on MCP</a>, and the quickstart is explicit that MCP is how apps expose tools to ChatGPT.</p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-official-mcp-support-for-google-services\">Google announced official MCP support</a> across Google and Google Cloud services, with an enterprise governance story (registry/hub + audit logging/IAM). </p></li></ul><p>The implication isn’t that MCP “wins” as a product. It’s that interoperability is becoming table stakes, and the hard work shifts upward: how you govern and operate tool access.</p><p></p><hr><h2>Governance is no longer optional (and it’s not just a security team concern)</h2><p>As agents move from “suggest” to “do,” governance stops being a policy doc and becomes runtime infrastructure.</p><p>This lines up with <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.gartner.com/en/articles/ai-trust-and-ai-risk\">Gartner’s AI TRiSM framing</a>: governance, monitoring, and operational controls as part of running AI systems. And Gartner has been <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.gartner.com/en/newsroom/press-releases/2025-11-19-gartner-identifies-critical-genai-blind-spots-that-cios-must-urgently-address0\">explicit about the risk side too</a>—predicting that by 2030, over 40% of enterprises will experience security or compliance incidents linked to unauthorized “shadow AI.” </p><p>So the enterprise question becomes practical:<strong> Where do we enforce permissions, audit trails, and cost controls—if not inside every single app?</strong> That’s what context infrastructure is for.</p><hr><h2>Requirement 1: Context infrastructure (what the foundation has to do)</h2><p>At scale, “connect the agent to tools” turns into a systems problem:</p><ul><li><p><strong>Connection sprawl: </strong>M MCP servers × N agents becomes M×N integrations, each with its own auth, config, failure modes.</p></li><li><p><strong>Observability gaps</strong>: when something breaks, you can’t answer “what ran, where, why, and what did it cost?”</p></li><li><p><strong>Governance gaps:</strong> permissions end up duplicated or inconsistent across apps; audit trails are partial.</p></li><li><p><strong>Tool discovery bloat: </strong>as tool surfaces grow, naively sending tool definitions everywhere gets expensive and can degrade performance.</p></li></ul><p>The ecosystem is responding with better runtime patterns. For example, Anthropic describes <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.anthropic.com/engineering/code-execution-with-mcp\">code execution with MCP</a> as a way to load tools on demand and keep heavy processing out of the model’s context window. </p><p>This is what we mean by “foundation”: centralize cross-cutting concerns (auth, policy, audit, routing, runtime strategies) so you don’t rebuild them in every application.</p><p>Read<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.google.com/document/d/1xBwoOIBiPV0sSqXKIl-1mhe7F5sgWFfSJulNW-MbCek/edit?tab=t.0\"> MCP Mesh Launch - blogpost 2 (tech)</a> for a deep dive into this layer: what an MCP Mesh is, and what it needs to support to be production-grade.</p><hr><h2>Requirement 2: Reusable building blocks (packaging and curation)</h2><p>Once tool access is stable, the next bottleneck is reuse.</p><p>Enterprises don’t fail because they lack tools. They fail because tool use stays ad hoc:</p><ul><li><p>teams reinvent similar connectors and prompts,</p></li><li><p>schemas drift,</p></li><li><p>permissions get bolted on late,</p></li><li><p>and “which agent is the real one?” becomes a social problem.</p></li></ul><p>So you need a builder framework where teams can package capabilities as durable assets:</p><ul><li><p>clear contracts (schemas),</p></li><li><p>explicit permissions/policies,</p></li><li><p>versioning and curation,</p></li><li><p>and a default path for other teams to adopt without rewiring everything.</p></li></ul><p>Think “packages” rather than “scripts.”</p><hr><h2>Requirement 3: Adoption without chaos (where work happens)</h2><p>Finally: where does the work actually run, and how do you spread it safely?</p><p>You need both ends:</p><ul><li><p>mission-critical apps that justify the governance and reliability work, and</p></li><li><p>long-tail internal apps that make teams faster in ways a central platform team will never have bandwidth to build.</p></li></ul><p>The point isn’t “a marketplace.” It’s distribution:</p><ul><li><p>across teams,</p></li><li><p>across environments (dev → prod),</p></li><li><p>and over time (capabilities evolve without everyone rewriting integrations).</p></li></ul><hr><h2>The architectural choice: flexible consolidation</h2><p>Most orgs end up choosing between two extremes:</p><ul><li><p><strong>Best-of-breed everywhere → </strong>maximum flexibility, maximum sprawl</p></li><li><p><strong>One vendor consolidator →</strong> simpler, but rigid, and often a new lock-in boundary</p><p></p></li></ul><p>The approach we think works better is<strong> flexible consolidation:</strong></p><ul><li><p>consolidate the infrastructure layer you shouldn’t rebuild (governance, observability, routing, cost controls),</p></li><li><p>keep the edges composable (swap models, swap MCP servers, adopt community MCPs, build your own when needed).</p></li></ul><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-official-mcp-support-for-google-services\">Google’s MCP push and managed servers</a> are a good example of this direction: standard protocol + enterprise governance controls, with space for organizations to expose their own APIs as tools. </p><hr><h2>What this means for deco </h2><p>deco’s Context Management System is our implementation of this architecture:</p><ul><li><p>MCP Mesh is the foundation: one governed endpoint for MCP traffic, with observability, access control, and runtime strategies.</p></li><li><p>MCP Studio is the builder layer: create and curate MCP-native capabilities as reusable assets.</p></li><li><p>MCP Apps + Store is how capabilities get used and distributed.</p></li></ul><p>If you want the technical details, the next post is the deep dive:</p><p>Building the Foundation for AI-Native Companies → (MCP Mesh architecture) </p><p></p>",
    "slug": "product"
  }
}